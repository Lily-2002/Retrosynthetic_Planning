{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lily-2002/Retrosynthetic_Planning/blob/main/train_mT5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnQnVdHa2B4U",
        "outputId": "c0858bea-d2f7-4621-b618-058c156f3dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QF3XVvYW11VW"
      },
      "outputs": [],
      "source": [
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm,trange\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import AutoTokenizer, MT5ForConditionalGeneration,MT5ForSequenceClassification,MT5Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a2VgoKVf17Gd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1895cef-7326-4381-95cb-69c3ab1a335b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CnsWZNrD2bfs"
      },
      "outputs": [],
      "source": [
        "def top_k_acc(preds, gt,k=1):\n",
        "    # preds = preds.to(torch.device('cpu'))\n",
        "    probs, idx = torch.topk(preds, k=k)\n",
        "    idx = idx.cpu().numpy().tolist()# idx前k个最大的值\n",
        "    gt = gt.cpu().numpy().tolist()\n",
        "    num = preds.size(0)\n",
        "    correct = 0\n",
        "    for i in range(num):\n",
        "        for id in idx[i]:\n",
        "            if id == gt[i]:\n",
        "                correct += 1\n",
        "    return correct, num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EQWyYOSH2e9U"
      },
      "outputs": [],
      "source": [
        "def tokenizers(X):\n",
        "  from transformers import MT5Tokenizer, MT5ForSequenceClassification\n",
        "  tokenizer = MT5Tokenizer.from_pretrained(\"/content/gdrive/MyDrive/mT5-small\")\n",
        "  inputs = tokenizer(X,padding=True,truncation=True,max_length=256,return_tensors=\"pt\")\n",
        "  return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Z1jbaPdG2hW0"
      },
      "outputs": [],
      "source": [
        "class OnestepDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super(OnestepDataset, self).__init__()\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        # self.fp_dim = fp_dim\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx],self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Kxg-Uof22kNN"
      },
      "outputs": [],
      "source": [
        "def dataset_iterator(X,y,\n",
        "          batch_size=1024,\n",
        "          shuffle=True\n",
        "          ):\n",
        "    dataset = OnestepDataset(X,y)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    import torch\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        X, y = zip(*batch)\n",
        "        from transformers import MT5Tokenizer, MT5ForSequenceClassification\n",
        "        tokenizer = MT5Tokenizer.from_pretrained(\"/content/gdrive/MyDrive/mT5-small\")\n",
        "        inputs = tokenizer(X,padding=True,truncation=True,max_length=256,return_tensors=\"pt\")\n",
        "        modified_y = [label - 1 for label in y]\n",
        "        return inputs, torch.tensor(modified_y)\n",
        "\n",
        "\n",
        "    return DataLoader(train_dataset,\n",
        "              batch_size=batch_size,\n",
        "              shuffle=shuffle,\n",
        "              collate_fn = collate_fn\n",
        "              ),DataLoader(val_dataset,\n",
        "                    batch_size = batch_size,\n",
        "                    shuffle= shuffle,\n",
        "                    collate_fn = collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4GEX_eqA2sqk"
      },
      "outputs": [],
      "source": [
        "def load_csv(path):\n",
        "    X, y = [], []\n",
        "    df = pd.read_csv(path)\n",
        "    num = len(df)\n",
        "    rnx_smiles = list(df['reactions'])\n",
        "    tnx_class = list(df['class'])\n",
        "    del df\n",
        "    for i in tqdm(range(num)):\n",
        "        rxn = rnx_smiles[i]\n",
        "        product = rxn.strip().split('>')[-1]\n",
        "        X.append(product)\n",
        "        y.append(tnx_class[i])\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qIl5PDjv2uqk"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader,\n",
        "          optimizer,\n",
        "          device,\n",
        "          loss_fn,\n",
        "          it):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    # print(train_loader)\n",
        "    for X_batch, y_batch in tqdm(train_loader):\n",
        "        y_batch = y_batch.to(device).long()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**X_batch, labels=y_batch)\n",
        "        print(y_batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        it.set_postfix(loss=np.mean(losses[-10:]) if losses else None)\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KxLtlMeq3Pi0"
      },
      "outputs": [],
      "source": [
        "def eval_one_epoch(model, val_loader,device):\n",
        "    model.eval()\n",
        "    eval_top1_correct, eval_top1_num = 0, 0\n",
        "    eval_top10_correct, eval_top10_num = 0, 0\n",
        "    eval_top50_correct, eval_top50_num = 0, 0\n",
        "    loss = 0.0\n",
        "    for X_batch, y_batch in tqdm(val_loader):\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        print(y_batch)\n",
        "        with torch.no_grad():\n",
        "            y_hat = model(**X_batch)\n",
        "            loss += F.cross_entropy(y_hat,y_batch).item()\n",
        "            top_1_correct, num1 = top_k_acc(y_hat, y_batch, k=1)\n",
        "            top_3_correct, num10 = top_k_acc(y_hat, y_batch, k=3)\n",
        "            top_5_correct, num50 = top_k_acc(y_hat, y_batch, k=5)\n",
        "            eval_top1_correct += top_1_correct\n",
        "            eval_top1_num += num1\n",
        "            eval_top10_correct += top_10_correct\n",
        "            eval_top10_num += num10\n",
        "            eval_top50_correct += top_50_correct\n",
        "            eval_top50_num += num50\n",
        "    val_1 = eval_top1_correct/eval_top1_num\n",
        "    val_10 = eval_top10_correct/eval_top10_num\n",
        "    val_50 = eval_top50_correct/eval_top50_num\n",
        "    loss = loss / (len(val_loader.dataset))\n",
        "    return val_1, val_10, val_50, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_RJe_XMT3SU0"
      },
      "outputs": [],
      "source": [
        "def train_mT5(model,data,\n",
        "          loss_fn = nn.CrossEntropyLoss(),\n",
        "          lr = 1e-4,\n",
        "          batch_size=16,\n",
        "          epochs=5,\n",
        "          wd=0,\n",
        "          saved_model='../model/saved_states'):\n",
        "    it = trange(epochs)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(),lr=lr,weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, min_lr=1e-6)\n",
        "    X,y = data\n",
        "    train_loader,val_loader  = dataset_iterator(X,y,batch_size=batch_size)\n",
        "    best = -1\n",
        "    for e in it:\n",
        "        # Iterate batches\n",
        "        train_one_epoch(model,train_loader,optimizer,device,loss_fn,it)\n",
        "        ## Do validation after one epoch training.\n",
        "        val_1,val_10, val_50, loss= eval_one_epoch(model,val_loader,device)\n",
        "        scheduler.step(loss)\n",
        "        if best < val_1:\n",
        "            best = val_1\n",
        "            state = model.state_dict()\n",
        "            torch.save(state,saved_model)\n",
        "        print(\"\\nTop 1: {}  ==> Top 10: {} ==> Top 50: {}, validation loss ==> {}\".format(val_1, val_10, val_50, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b99nIMOn3U1k",
        "outputId": "6da9f97b-3d11-4ce0-a8c9-113a07150edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50016/50016 [00:00<00:00, 1056029.18it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\n",
            "  0%|          | 0/2501 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 8, 5, 2, 0, 5, 1, 5, 1, 6, 1, 8, 0, 1, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:23<?, ?it/s, loss=2.52]\n",
            "  0%|          | 1/2501 [00:23<16:21:09, 23.55s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 1, 6, 1, 1, 1, 0, 1, 5, 1, 0, 0, 0, 8, 1, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:39<?, ?it/s, loss=2.22]\n",
            "  0%|          | 2/2501 [00:39<13:08:52, 18.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 0, 5, 0, 2, 4, 1, 0, 1, 1, 6, 0, 6, 0, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [01:04<?, ?it/s, loss=2.21]\n",
            "  0%|          | 3/2501 [01:04<15:06:00, 21.76s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 1, 1, 5, 1, 2, 1, 0, 2, 1, 2, 7, 1, 4, 0, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [01:20<?, ?it/s, loss=2.23]\n",
            "  0%|          | 4/2501 [01:20<13:36:13, 19.61s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 0, 5, 0, 2, 0, 1, 5, 6, 2, 8, 2, 5, 1, 6])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [01:41<?, ?it/s, loss=2.16]\n",
            "  0%|          | 5/2501 [01:41<13:54:17, 20.05s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 8, 2, 0, 7, 1, 0, 2, 2, 0, 2, 6, 2, 0, 5, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [01:50<?, ?it/s, loss=2.15]\n",
            "  0%|          | 6/2501 [01:50<11:15:29, 16.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 0, 5, 6, 5, 8, 5, 0, 5, 1, 5, 1, 8, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [02:02<?, ?it/s, loss=2.25]\n",
            "  0%|          | 7/2501 [02:02<10:22:20, 14.97s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 1, 0, 1, 1, 1, 1, 5, 1, 0, 6, 0, 5, 8, 5, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [02:14<?, ?it/s, loss=2.3] \n",
            "  0%|          | 8/2501 [02:14<9:38:48, 13.93s/it] \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 5, 6, 0, 0, 0, 6, 0, 5, 2, 5, 2, 5, 0, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [02:27<?, ?it/s, loss=2.22]\n",
            "  0%|          | 9/2501 [02:27<9:25:30, 13.62s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 0, 2, 2, 0, 1, 7, 1, 8, 1, 6, 1, 4, 1, 8])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [02:39<?, ?it/s, loss=2.25]\n",
            "  0%|          | 10/2501 [02:38<8:59:45, 13.00s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 5, 0, 9, 0, 7, 6, 1, 6, 5, 8, 5, 6, 5, 1, 7])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [02:49<?, ?it/s, loss=2.25]\n",
            "  0%|          | 11/2501 [02:49<8:28:21, 12.25s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 0, 1, 0, 6, 1, 8, 8, 7, 1, 0, 8, 5, 5, 0, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [02:59<?, ?it/s, loss=2.24]\n",
            "  0%|          | 12/2501 [02:59<8:03:14, 11.65s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 5, 7, 5, 4, 0, 1, 1, 0, 1, 1, 2, 0, 0, 5, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [03:11<?, ?it/s, loss=2.2] \n",
            "  1%|          | 13/2501 [03:11<8:03:22, 11.66s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 0, 0, 6, 7, 1, 2, 0, 1, 5, 3, 2, 0, 1, 0, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [03:23<?, ?it/s, loss=2.19]\n",
            "  1%|          | 14/2501 [03:23<8:13:35, 11.91s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 5, 5, 0, 6, 5, 0, 0, 0, 4, 6, 0, 2, 1, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [03:35<?, ?it/s, loss=2.2] \n",
            "  1%|          | 15/2501 [03:35<8:14:28, 11.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 2, 0, 5, 6, 0, 0, 1, 0, 5, 0, 0, 5, 8, 1, 6])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [03:48<?, ?it/s, loss=2.16]\n",
            "  1%|          | 16/2501 [03:48<8:19:56, 12.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 0, 0, 0, 4, 1, 0, 5, 5, 5, 5, 2, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [04:01<?, ?it/s, loss=2.04]\n",
            "  1%|          | 17/2501 [04:01<8:35:09, 12.44s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 5, 1, 1, 2, 0, 5, 0, 5, 5, 0, 0, 0, 2, 5, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [04:12<?, ?it/s, loss=1.93]\n",
            "  1%|          | 18/2501 [04:12<8:13:17, 11.92s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 0, 5, 5, 0, 1, 1, 6, 1, 1, 0, 5, 6, 5, 8, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [04:23<?, ?it/s, loss=1.97]\n",
            "  1%|          | 19/2501 [04:23<8:01:31, 11.64s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 5, 6, 0, 4, 7, 5, 1, 0, 5, 1, 1, 1, 5, 1, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [04:35<?, ?it/s, loss=1.91]\n",
            "  1%|          | 20/2501 [04:35<8:13:09, 11.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 8, 1, 0, 2, 1, 1, 0, 0, 6, 0, 0, 5, 2, 2, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [04:46<?, ?it/s, loss=1.86]\n",
            "  1%|          | 21/2501 [04:46<8:01:40, 11.65s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 0, 0, 6, 6, 0, 4, 6, 1, 2, 2, 4, 1, 2, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [04:58<?, ?it/s, loss=1.91]\n",
            "  1%|          | 22/2501 [04:58<8:03:23, 11.70s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 8, 0, 2, 0, 1, 0, 8, 2, 0, 0, 6, 5, 2, 6])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [05:08<?, ?it/s, loss=1.98]\n",
            "  1%|          | 23/2501 [05:08<7:40:15, 11.14s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 0, 1, 0, 0, 6, 5, 1, 0, 0, 5, 5, 1, 8, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [05:19<?, ?it/s, loss=1.94]\n",
            "  1%|          | 24/2501 [05:19<7:31:01, 10.92s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 0, 1, 0, 5, 0, 0, 1, 0, 1, 2, 0, 2, 1, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [05:30<?, ?it/s, loss=1.89]\n",
            "  1%|          | 25/2501 [05:30<7:40:35, 11.16s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 0, 0, 1, 5, 1, 0, 0, 1, 0, 0, 1, 1, 5, 4, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [05:42<?, ?it/s, loss=1.87]\n",
            "  1%|          | 26/2501 [05:42<7:42:56, 11.22s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 1, 5, 1, 5, 5, 5, 5, 0, 5, 5, 8, 4, 4, 5, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [05:51<?, ?it/s, loss=1.98]\n",
            "  1%|          | 27/2501 [05:51<7:24:57, 10.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 1, 1, 6, 5, 5, 5, 6, 2, 2, 0, 0, 6, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [06:04<?, ?it/s, loss=2.06]\n",
            "  1%|          | 28/2501 [06:04<7:44:34, 11.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 2, 5, 0, 5, 2, 2, 0, 5, 8, 0, 5, 2, 0, 2, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [06:16<?, ?it/s, loss=2.07]\n",
            "  1%|          | 29/2501 [06:16<8:01:12, 11.68s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 8, 0, 0, 0, 0, 5, 1, 0, 2, 5, 0, 6, 1, 6, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [06:29<?, ?it/s, loss=2.03]\n",
            "  1%|          | 30/2501 [06:29<8:13:45, 11.99s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 5, 6, 5, 1, 0, 2, 4, 0, 5, 6, 1, 5, 0, 0, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [06:44<?, ?it/s, loss=2.02]\n",
            "  1%|          | 31/2501 [06:44<8:54:30, 12.98s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 1, 0, 7, 1, 7, 1, 2, 5, 0, 8, 5, 1, 6, 1, 8])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [06:56<?, ?it/s, loss=2.01]\n",
            "  1%|▏         | 32/2501 [06:56<8:38:59, 12.61s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 6, 1, 7, 0, 0, 1, 6, 5, 5, 5, 0, 0, 0, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [07:09<?, ?it/s, loss=1.93]\n",
            "  1%|▏         | 33/2501 [07:09<8:38:29, 12.61s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 1, 3, 0, 1, 0, 2, 2, 2, 2, 0, 6, 0, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [07:20<?, ?it/s, loss=1.96]\n",
            "  1%|▏         | 34/2501 [07:20<8:17:28, 12.10s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 8, 5, 5, 2, 5, 5, 6, 3, 6, 5, 2, 6, 0, 5, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [07:29<?, ?it/s, loss=2]   \n",
            "  1%|▏         | 35/2501 [07:29<7:48:45, 11.41s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 0, 5, 0, 6, 1, 1, 1, 6, 1, 1, 2, 1, 1, 6, 3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [07:42<?, ?it/s, loss=2.04]\n",
            "  1%|▏         | 36/2501 [07:42<8:04:15, 11.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 6, 0, 5, 5, 8, 0, 0, 2, 4, 0, 6, 7, 5, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [07:53<?, ?it/s, loss=2]   \n",
            "  1%|▏         | 37/2501 [07:53<7:56:44, 11.61s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 1, 1, 5, 0, 5, 8, 0, 0, 0, 2, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [08:07<?, ?it/s, loss=1.97]\n",
            "  2%|▏         | 38/2501 [08:07<8:16:58, 12.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 1, 5, 0, 5, 0, 0, 0, 1, 0, 0, 5, 0, 2, 1])\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    X_train,y_train = load_csv(\"/content/gdrive/MyDrive/USPTO_50K.csv\")\n",
        "    config = MT5Config.from_pretrained(\"/content/gdrive/MyDrive/mT5-small\")\n",
        "    config.problem_type = \"single_label_classification\"  # 设置 problem_type\n",
        "    config.num_labels = 10\n",
        "    # 使用配置创建 MT5ForSequenceClassification 的实例\n",
        "    model = MT5ForSequenceClassification(config)\n",
        "    data = (X_train,y_train)\n",
        "    train_mT5(model, data, lr=1e-4, batch_size=16, epochs=5, wd=0, saved_model='/content/gdrive/MyDrive/sft_mT5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpE1st581ZkNAWhS4blrgr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}